<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>使用 logstash 采集来自腾讯云 tke 的日志 | johnpoint's blog</title>
<meta name=keywords content="logstash,腾讯云,笔记"><meta name=description content='前提
好久没有给博客除草了，正好最近折腾了下 logstash，记录一下。
为啥要用 logstash 呢，其实是因为在测试环境上面腾讯云 tke 的日志没有开启日志收集，所以在排查问题的时候会十分的痛苦，正好有空了就想着将日志抽出来放进 es 里面，方便以后排查问题，正好看到腾讯云的日志规则是允许将 pod 的 stdout 日志进行采集之后投递到 kafka 的，就小试了一下。
部署 logstash
logstash 我选择使用 docker-compose 来进行快速的部署。
以下是部署流程，参考自 deviantony/docker-elk 项目
创建目录
mkdir logstash/config logstash/pipeline -p
创建环境变量
路径 .env
ELASTIC_VERSION=8.7.1
LOGSTASH_INTERNAL_PASSWORD=&#39;changeme&#39;
创建 Dockerfile
路径 logstasg/Dockerfile
ARG ELASTIC_VERSION

# https://www.docker.elastic.co/
FROM docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}
配置文件
路径 logstash/config/logstash.yml
---
## Default Logstash configuration from Logstash base image.
## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml
#
http.host: 0.0.0.0

node.name: logstash
路径 logstash/pipeline/logstash.conf
input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
		index => "logstash-%{+YYYY-MM-dd}"
	}
}
启动服务
version: &#39;3.7&#39;

services:
  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    depends_on:
      - elasticsearch
    restart: unless-stopped
配置 logstash pipeline
配置 input
因为日志要从 kafka 读取，所以要在 input 块内声明一个新的数据源'><meta name=author content="johnpoint"><link rel=canonical href=https://blog.lvcshu.com/2023/05/15/%E4%BD%BF%E7%94%A8-logstash-%E9%87%87%E9%9B%86%E6%9D%A5%E8%87%AA%E8%85%BE%E8%AE%AF%E4%BA%91-tke-%E7%9A%84%E6%97%A5%E5%BF%97/><link crossorigin=anonymous href=/assets/css/stylesheet.9a07b9c81cbc95fa741d61ca6489dcdb8491591c19dca31d14a124a4ba95ec80.css integrity="sha256-mge5yBy8lfp0HWHKZInc24SRWRwZ3KMdFKEkpLqV7IA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://blog.lvcshu.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.lvcshu.com/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://blog.lvcshu.com/favicon.ico><link rel=apple-touch-icon href=https://blog.lvcshu.com/favicon.ico><link rel=mask-icon href=https://blog.lvcshu.com/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.lvcshu.com/2023/05/15/%E4%BD%BF%E7%94%A8-logstash-%E9%87%87%E9%9B%86%E6%9D%A5%E8%87%AA%E8%85%BE%E8%AE%AF%E4%BA%91-tke-%E7%9A%84%E6%97%A5%E5%BF%97/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="使用 logstash 采集来自腾讯云 tke 的日志"><meta property="og:description" content='前提
好久没有给博客除草了，正好最近折腾了下 logstash，记录一下。
为啥要用 logstash 呢，其实是因为在测试环境上面腾讯云 tke 的日志没有开启日志收集，所以在排查问题的时候会十分的痛苦，正好有空了就想着将日志抽出来放进 es 里面，方便以后排查问题，正好看到腾讯云的日志规则是允许将 pod 的 stdout 日志进行采集之后投递到 kafka 的，就小试了一下。
部署 logstash
logstash 我选择使用 docker-compose 来进行快速的部署。
以下是部署流程，参考自 deviantony/docker-elk 项目
创建目录
mkdir logstash/config logstash/pipeline -p
创建环境变量
路径 .env
ELASTIC_VERSION=8.7.1
LOGSTASH_INTERNAL_PASSWORD=&#39;changeme&#39;
创建 Dockerfile
路径 logstasg/Dockerfile
ARG ELASTIC_VERSION

# https://www.docker.elastic.co/
FROM docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}
配置文件
路径 logstash/config/logstash.yml
---
## Default Logstash configuration from Logstash base image.
## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml
#
http.host: 0.0.0.0

node.name: logstash
路径 logstash/pipeline/logstash.conf
input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
		index => "logstash-%{+YYYY-MM-dd}"
	}
}
启动服务
version: &#39;3.7&#39;

services:
  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    depends_on:
      - elasticsearch
    restart: unless-stopped
配置 logstash pipeline
配置 input
因为日志要从 kafka 读取，所以要在 input 块内声明一个新的数据源'><meta property="og:type" content="article"><meta property="og:url" content="https://blog.lvcshu.com/2023/05/15/%E4%BD%BF%E7%94%A8-logstash-%E9%87%87%E9%9B%86%E6%9D%A5%E8%87%AA%E8%85%BE%E8%AE%AF%E4%BA%91-tke-%E7%9A%84%E6%97%A5%E5%BF%97/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-15T10:34:44+08:00"><meta property="article:modified_time" content="2023-05-15T10:34:44+08:00"><meta property="og:site_name" content="johnpoint's blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="使用 logstash 采集来自腾讯云 tke 的日志"><meta name=twitter:description content='前提
好久没有给博客除草了，正好最近折腾了下 logstash，记录一下。
为啥要用 logstash 呢，其实是因为在测试环境上面腾讯云 tke 的日志没有开启日志收集，所以在排查问题的时候会十分的痛苦，正好有空了就想着将日志抽出来放进 es 里面，方便以后排查问题，正好看到腾讯云的日志规则是允许将 pod 的 stdout 日志进行采集之后投递到 kafka 的，就小试了一下。
部署 logstash
logstash 我选择使用 docker-compose 来进行快速的部署。
以下是部署流程，参考自 deviantony/docker-elk 项目
创建目录
mkdir logstash/config logstash/pipeline -p
创建环境变量
路径 .env
ELASTIC_VERSION=8.7.1
LOGSTASH_INTERNAL_PASSWORD=&#39;changeme&#39;
创建 Dockerfile
路径 logstasg/Dockerfile
ARG ELASTIC_VERSION

# https://www.docker.elastic.co/
FROM docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}
配置文件
路径 logstash/config/logstash.yml
---
## Default Logstash configuration from Logstash base image.
## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml
#
http.host: 0.0.0.0

node.name: logstash
路径 logstash/pipeline/logstash.conf
input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
		index => "logstash-%{+YYYY-MM-dd}"
	}
}
启动服务
version: &#39;3.7&#39;

services:
  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    depends_on:
      - elasticsearch
    restart: unless-stopped
配置 logstash pipeline
配置 input
因为日志要从 kafka 读取，所以要在 input 块内声明一个新的数据源'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.lvcshu.com/posts/"},{"@type":"ListItem","position":2,"name":"使用 logstash 采集来自腾讯云 tke 的日志","item":"https://blog.lvcshu.com/2023/05/15/%E4%BD%BF%E7%94%A8-logstash-%E9%87%87%E9%9B%86%E6%9D%A5%E8%87%AA%E8%85%BE%E8%AE%AF%E4%BA%91-tke-%E7%9A%84%E6%97%A5%E5%BF%97/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"使用 logstash 采集来自腾讯云 tke 的日志","name":"使用 logstash 采集来自腾讯云 tke 的日志","description":"前提 好久没有给博客除草了，正好最近折腾了下 logstash，记录一下。\n为啥要用 logstash 呢，其实是因为在测试环境上面腾讯云 tke 的日志没有开启日志收集，所以在排查问题的时候会十分的痛苦，正好有空了就想着将日志抽出来放进 es 里面，方便以后排查问题，正好看到腾讯云的日志规则是允许将 pod 的 stdout 日志进行采集之后投递到 kafka 的，就小试了一下。\n部署 logstash logstash 我选择使用 docker-compose 来进行快速的部署。\n以下是部署流程，参考自 deviantony/docker-elk 项目\n创建目录 mkdir logstash/config logstash/pipeline -p 创建环境变量 路径 .env\nELASTIC_VERSION=8.7.1 LOGSTASH_INTERNAL_PASSWORD=\u0026#39;changeme\u0026#39; 创建 Dockerfile 路径 logstasg/Dockerfile\nARG ELASTIC_VERSION # https://www.docker.elastic.co/ FROM docker.elastic.co/logstash/logstash:${ELASTIC_VERSION} 配置文件 路径 logstash/config/logstash.yml\n--- ## Default Logstash configuration from Logstash base image. ## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml # http.host: 0.0.0.0 node.name: logstash 路径 logstash/pipeline/logstash.conf\ninput { beats { port =\u0026gt; 5044 } tcp { port =\u0026gt; 50000 } } ## Add your filters / logstash plugins configuration here output { elasticsearch { hosts =\u0026gt; \u0026#34;elasticsearch:9200\u0026#34; user =\u0026gt; \u0026#34;logstash_internal\u0026#34; password =\u0026gt; \u0026#34;${LOGSTASH_INTERNAL_PASSWORD}\u0026#34; index =\u0026gt; \u0026#34;logstash-%{+YYYY-MM-dd}\u0026#34; } } 启动服务 version: \u0026#39;3.7\u0026#39; services: logstash: build: context: logstash/ args: ELASTIC_VERSION: ${ELASTIC_VERSION} volumes: - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z ports: - 5044:5044 - 50000:50000/tcp - 50000:50000/udp - 9600:9600 environment: LS_JAVA_OPTS: -Xms256m -Xmx256m LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-} depends_on: - elasticsearch restart: unless-stopped 配置 logstash pipeline 配置 input 因为日志要从 kafka 读取，所以要在 input 块内声明一个新的数据源\n","keywords":["logstash","腾讯云","笔记"],"articleBody":"前提 好久没有给博客除草了，正好最近折腾了下 logstash，记录一下。\n为啥要用 logstash 呢，其实是因为在测试环境上面腾讯云 tke 的日志没有开启日志收集，所以在排查问题的时候会十分的痛苦，正好有空了就想着将日志抽出来放进 es 里面，方便以后排查问题，正好看到腾讯云的日志规则是允许将 pod 的 stdout 日志进行采集之后投递到 kafka 的，就小试了一下。\n部署 logstash logstash 我选择使用 docker-compose 来进行快速的部署。\n以下是部署流程，参考自 deviantony/docker-elk 项目\n创建目录 mkdir logstash/config logstash/pipeline -p 创建环境变量 路径 .env\nELASTIC_VERSION=8.7.1 LOGSTASH_INTERNAL_PASSWORD='changeme' 创建 Dockerfile 路径 logstasg/Dockerfile\nARG ELASTIC_VERSION # https://www.docker.elastic.co/ FROM docker.elastic.co/logstash/logstash:${ELASTIC_VERSION} 配置文件 路径 logstash/config/logstash.yml\n--- ## Default Logstash configuration from Logstash base image. ## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml # http.host: 0.0.0.0 node.name: logstash 路径 logstash/pipeline/logstash.conf\ninput { beats { port =\u003e 5044 } tcp { port =\u003e 50000 } } ## Add your filters / logstash plugins configuration here output { elasticsearch { hosts =\u003e \"elasticsearch:9200\" user =\u003e \"logstash_internal\" password =\u003e \"${LOGSTASH_INTERNAL_PASSWORD}\" index =\u003e \"logstash-%{+YYYY-MM-dd}\" } } 启动服务 version: '3.7' services: logstash: build: context: logstash/ args: ELASTIC_VERSION: ${ELASTIC_VERSION} volumes: - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z ports: - 5044:5044 - 50000:50000/tcp - 50000:50000/udp - 9600:9600 environment: LS_JAVA_OPTS: -Xms256m -Xmx256m LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-} depends_on: - elasticsearch restart: unless-stopped 配置 logstash pipeline 配置 input 因为日志要从 kafka 读取，所以要在 input 块内声明一个新的数据源\ninput { beats { port =\u003e 5044 } tcp { port =\u003e 50000 } kafka { bootstrap_servers =\u003e \"kafka 地址\" client_id =\u003e \"test_logstash\" group_id =\u003e \"test_logstash\" auto_offset_reset =\u003e \"latest\" consumer_threads =\u003e 1 decorate_events =\u003e true topics =\u003e [\"tencent-tke-log\"] type =\u003e \"bhy\" } } 配置过滤器 由于腾讯云投递到kafka的数据不是可以直接用的，数据示例如下\n{\"@timestamp\":1684203000.007603,\"@filepath\":\"/var/log/tke-log-agent/log/stdout-containerd/xxxxxxx.log\",\"log\":\"2023-05-16T10:10:00.002817673+08:00 stdout F {\\\"level\\\":\\\"debug\\\",\\\"time\\\":\\\"2023-05-16T10:10:00.002+0800\\\",\\\"msg\\\":\\\"xxxxxxxx\\\"}\",\"kubernetes\":{\"pod_name\":\"xxxxx\",\"namespace_name\":\"default\",\"pod_id\":\"xxxxxx\",\"labels\":{\"k8s-app\":\"xxxxx\",\"pod-template-hash\":\"xxxxx\",\"qcloud-app\":\"xxxxxxxx\"},\"annotations\":{\"qcloud-redeploy-timestamp\":\"1681975158658\",\"tke.cloud.tencent.com/networks-status\":\"json\"},\"host\":\"xxxxx\",\"container_name\":\"xxxx\",\"docker_id\":\"xxxxx\",\"container_hash\":\"xxxxxx\",\"container_image\":\"xxxxxxxx\"}} 这时候就要对数据进行预处理，因为有很多数据是不需要添加进入es里面的。使用了 logstags 的 filter 进行处理。\n保存原始数据 这个过滤器添加了一个叫做 source 的字段，并且将 kafka 消息全部存储在里面\nmutate { add_field =\u003e { \"source\" =\u003e \"%{[message]}\" } } 解析 json 使用 json 插件，对 message 字段的 json 字符串进行序列化，并且将序列化后的数据存储在 kafkajson 字段内，同时删除 message 字段\njson { source =\u003e \"message\" remove_field =\u003e [ \"message\" ] target =\u003e \"kafkajson\" } 提取日志元数据 将日志中的一些定位数据提取到外层\nmutate { rename =\u003e { \"[kafkajson][kubernetes][namespace_name]\" =\u003e \"namespace\" } rename =\u003e { \"[kafkajson][kubernetes][pod_name]\" =\u003e \"podname\" } rename =\u003e { \"[kafkajson][kubernetes][labels][k8s-app]\" =\u003e \"k8s-app\" } rename =\u003e { \"[kafkajson][kubernetes][container_image]\" =\u003e \"container-image\" } } 使用正则表达式处理数据 腾讯云给出的数据会在服务自己打印的日志前方添加时间以及 ”stdout F“，所以要使用正则表达式将我们不需要的东西做下替换\n2023-05-16T10:10:00.002817673+08:00 stdout F {\\\"level\\\":\\\"debug\\\",\\\"time\\\":\\\"2023-05-16T10:10:00.002+0800\\\",\\\"msg\\\":\\\"xxxxx\\\"} mutate { gsub =\u003e [ \"[kafkajson][log]\",\".+stdout\\sF\\s\",\"\" ] } 提取服务打印的日志 这回终于可以将日志提取出来了\njson { source =\u003e \"[kafkajson][log]\" remove_field =\u003e [ \"kafkajson\" ] target =\u003e \"data\" } 提取日志等级 最后一步，将日志的等级字段提取到外层，方便使用\nmutate { rename =\u003e { \"[data][level]\" =\u003e \"level\" } } 完整 pipeline input { beats { port =\u003e 5044 } tcp { port =\u003e 50000 } kafka{ bootstrap_servers =\u003e \"kafka 地址\" client_id =\u003e \"test_logstash\" group_id =\u003e \"test_logstash\" auto_offset_reset =\u003e \"latest\" consumer_threads =\u003e 1 decorate_events =\u003e true topics =\u003e [\"tencent-tke-log\"] type =\u003e \"bhy\" } } filter { mutate { add_field =\u003e { \"source\" =\u003e \"%{[message]}\" } } json { source =\u003e \"message\" remove_field =\u003e [ \"message\" ] target =\u003e \"kafkajson\" } mutate { rename =\u003e { \"[kafkajson][kubernetes][namespace_name]\" =\u003e \"namespace\" } rename =\u003e { \"[kafkajson][kubernetes][pod_name]\" =\u003e \"podname\" } rename =\u003e { \"[kafkajson][kubernetes][labels][k8s-app]\" =\u003e \"k8s-app\" } rename =\u003e { \"[kafkajson][kubernetes][container_image]\" =\u003e \"container-image\" } } mutate { gsub =\u003e [ \"[kafkajson][log]\",\".+stdout\\sF\\s\",\"\" ] } json { source =\u003e \"[kafkajson][log]\" remove_field =\u003e [ \"kafkajson\" ] target =\u003e \"data\" } mutate { rename =\u003e { \"[data][level]\" =\u003e \"level\" } } } ## Add your filters / logstash plugins configuration here output { elasticsearch { hosts =\u003e \"elasticsearch:9200\" user =\u003e \"logstash_internal\" password =\u003e \"${LOGSTASH_INTERNAL_PASSWORD}\" index =\u003e \"logstash-%{+YYYY-MM-dd}\" } } 特别鸣谢 在本次配置 logstash 的过程中，我自己搭建的、使用 openAPI API 的、基于 GPT3.5 语言模型的 telegram bot 给予了我很大的帮助。\n以下是我与它的对话(对话内容经过处理)\njohnpoint, [5/15/23 2:18 PM] 我想从 2023-05-15T13:51:00.004687384+08:00 stdout F {\"level\":\"debug\",\"time\":\"2023-05-15T13:51:00.002+0800\",\"msg\":\"xxxxxxxx\"} 这些数据里面使用logstash 提取出json数据，logstash 的pipeline该怎么写 openAI, [5/15/23 2:18 PM] 假设你的日志文件是以JSON格式输出的，你需要配置一个JSON解析器来解析日志中的JSON数据，并将其转换为可用的事件。以下是一个简单的Logstash配置文件： ``` input { file { path =\u003e \"/path/to/your/logfile\" start_position =\u003e \"beginning\" sincedb_path =\u003e \"/dev/null\" } } filter { json { source =\u003e \"message\" } } output { stdout { codec =\u003e rubydebug } } ``` 在logstash的input部分，我们指定读取的文件的路径，以及从文件的开始位置开始读入数据。 在filter部分，我们使用`json`插件从日志中提取json对象。 最后，我们在output部分使用`rubydebug`进行输出。 运行这个Logstash的配置命令： ``` bin/logstash -f /path/to/your/config/file ``` 这样，logstash就会从你指定的文件中读取数据，并把提取的JSON对象输出到控制台上。 johnpoint, [5/15/23 2:19 PM] 这个数据有json格式的数据，但是在json格式的数据前面还有一些脏数据，是否可以去除？ openAI, [5/15/23 2:19 PM] 可以，在使用 logstash 分析数据的时候，可以使用 grok 这个插件，通过正则表达式匹配出需要的数据。 以下是一个可能符合你提供的数据的 grok 表达式： ``` %{TIMESTAMP_ISO8601:timestamp} stdout F %{GREEDYDATA:json_data} ``` 这个正则表达式的含义是匹配以 ISO8601 格式表示的时间戳（如 \"2023-05-15T13:51:00.004687384+08:00\"）和以字符串 \"stdout F \" 结尾的内容，然后跟着一个 Json 格式的字符串。\"%{GREEDYDATA:json_data}\" 表示将这个字符串保存到一个名为 \"json_data\" 的字段中。 上述 grok 表达式可以在 Logstash 的配置文件中使用，例如： ``` input { # 配置 logstash 接收数据的源 } filter { grok { match =\u003e { \"message\" =\u003e \"%{TIMESTAMP_ISO8601:timestamp} stdout F %{GREEDYDATA:json_data}\" } } # 其他过滤器 } output { # 配置 logstash 输出数据的目标 } ``` 这个配置文件中，通过 filter 下的 grok 插件匹配出了 timestamp 和 json_data 两个字段。从而可以使用 logstash 利用这些数据进行更进一步的操作，如输出到 Elasticsearch 或者 stdout。达到你想要的结果。 其中 `%{TIMESTAMP_ISO8601:timestamp}` 表示匹配 ISO8601 格式的时间戳，并将其保存到一个名为 \"timestamp\" 的字段中。`%{GREEDYDATA:json_data}` 表示匹配任意字符，可以匹配行末附加的不符合 Json 格式的内容。因为 grok 会一直匹配到行尾，所以匹配过程中会包括最后一个字段（即 json_data）中包含的所有内容。 johnpoint, [5/15/23 2:36 PM] 返回 Can't get text on a START_OBJECT at 1:8 是什么错误 openAI, [5/15/23 2:36 PM] 这个错误常见于尝试将 JSON 对象作为字符串进行解析的情况下，但是实际上得到的是 JSON 对象，而不是字符串。这意味着该对象的开头是一个“{”，而不是一个“\"”。可以检查代码调用的函数或方法，以确保解析的字符串确实是一个字符串。另外，可以检查 JSON 对象的源代码，以确保它是按照预期格式进行编写的。 johnpoint, [5/15/23 2:53 PM] [2023-05-15T06:52:48,511][WARN ][logstash.filters.json ][main][xxxxxx] Error parsing json {:source=\u003e\"json_data\", :raw=\u003e\"{\\\\\\\"level\\\\\\\":\\\\\\\"debug\\\\\\\",\\\\\\\"time\\\\\\\":\\\\\\\"2023-05-15T14:52:47.664+0800\\\\\\\",\\\\\\\"msg\\\\\\\":\\\\\\\"xxxxxxxx\\\\\\\"}\\\", \\\"@timestamp\\\"=\u003e0.1684133567674155e10}\", :exception=\u003e#","wordCount":"1200","inLanguage":"en","datePublished":"2023-05-15T10:34:44+08:00","dateModified":"2023-05-15T10:34:44+08:00","author":{"@type":"Person","name":"johnpoint"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.lvcshu.com/2023/05/15/%E4%BD%BF%E7%94%A8-logstash-%E9%87%87%E9%9B%86%E6%9D%A5%E8%87%AA%E8%85%BE%E8%AE%AF%E4%BA%91-tke-%E7%9A%84%E6%97%A5%E5%BF%97/"},"publisher":{"@type":"Organization","name":"johnpoint's blog","logo":{"@type":"ImageObject","url":"https://blog.lvcshu.com/favicon.ico"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://blog.lvcshu.com/ accesskey=h title="johnpoint's blog (Alt + H)">johnpoint's blog</a><div class=logo-switches><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://blog.lvcshu.com/posts/ title=归档><span>归档</span></a></li><li><a href=https://blog.lvcshu.com/friends/ title=友链><span>友链</span></a></li><li><a href=https://blog.lvcshu.com/about/ title=关于我><span>关于我</span></a></li><li><a href=https://blog.lvcshu.com/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">使用 logstash 采集来自腾讯云 tke 的日志</h1><div class=post-meta><span title='2023-05-15 10:34:44 +0800 CST'>2023-05-15 10:34:44</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1200 words&nbsp;·&nbsp;johnpoint</div></header><div class=post-content><h2 id=前提>前提<a hidden class=anchor aria-hidden=true href=#前提>#</a></h2><p>好久没有给博客除草了，正好最近折腾了下 logstash，记录一下。</p><p>为啥要用 logstash 呢，其实是因为在测试环境上面腾讯云 tke 的日志没有开启日志收集，所以在排查问题的时候会十分的痛苦，正好有空了就想着将日志抽出来放进 es 里面，方便以后排查问题，正好看到腾讯云的日志规则是允许将 pod 的 stdout 日志进行采集之后投递到 kafka 的，就小试了一下。</p><h2 id=部署-logstash>部署 logstash<a hidden class=anchor aria-hidden=true href=#部署-logstash>#</a></h2><p>logstash 我选择使用 docker-compose 来进行快速的部署。</p><p>以下是部署流程，参考自 <a href=https://github.com/deviantony/docker-elk>deviantony/docker-elk</a> 项目</p><h3 id=创建目录>创建目录<a hidden class=anchor aria-hidden=true href=#创建目录>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>mkdir logstash/config logstash/pipeline -p
</span></span></code></pre></div><h3 id=创建环境变量>创建环境变量<a hidden class=anchor aria-hidden=true href=#创建环境变量>#</a></h3><p>路径 <code>.env</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=na>ELASTIC_VERSION</span><span class=o>=</span><span class=s>8.7.1</span>
</span></span><span class=line><span class=cl><span class=na>LOGSTASH_INTERNAL_PASSWORD</span><span class=o>=</span><span class=s>&#39;changeme&#39;</span>
</span></span></code></pre></div><h3 id=创建-dockerfile>创建 Dockerfile<a hidden class=anchor aria-hidden=true href=#创建-dockerfile>#</a></h3><p>路径 <code>logstasg/Dockerfile</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-Dockerfile data-lang=Dockerfile><span class=line><span class=cl><span class=k>ARG</span> ELASTIC_VERSION<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># https://www.docker.elastic.co/</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}</span><span class=err>
</span></span></span></code></pre></div><h3 id=配置文件>配置文件<a hidden class=anchor aria-hidden=true href=#配置文件>#</a></h3><p>路径 <code>logstash/config/logstash.yml</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yml data-lang=yml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c>## Default Logstash configuration from Logstash base image.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c>## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c>#</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>http.host</span><span class=p>:</span><span class=w> </span><span class=m>0.0.0.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>node.name</span><span class=p>:</span><span class=w> </span><span class=l>logstash</span><span class=w>
</span></span></span></code></pre></div><p>路径 <code>logstash/pipeline/logstash.conf</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl><span class=n>input</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>beats</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>port</span> <span class=o>=&gt;</span> <span class=mi>5044</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>tcp</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>port</span> <span class=o>=&gt;</span> <span class=mi>50000</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Add your filters / logstash plugins configuration here</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>elasticsearch</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>hosts</span> <span class=o>=&gt;</span> <span class=s2>&#34;elasticsearch:9200&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>user</span> <span class=o>=&gt;</span> <span class=s2>&#34;logstash_internal&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>password</span> <span class=o>=&gt;</span> <span class=s2>&#34;${LOGSTASH_INTERNAL_PASSWORD}&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>index</span> <span class=o>=&gt;</span> <span class=s2>&#34;logstash-%{+YYYY-MM-dd}&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=启动服务>启动服务<a hidden class=anchor aria-hidden=true href=#启动服务>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;3.7&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>logstash</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>context</span><span class=p>:</span><span class=w> </span><span class=l>logstash/</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>args</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>ELASTIC_VERSION</span><span class=p>:</span><span class=w> </span><span class=l>${ELASTIC_VERSION}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=m>5044</span><span class=p>:</span><span class=m>5044</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=m>50000</span><span class=p>:</span><span class=m>50000</span><span class=l>/tcp</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=m>50000</span><span class=p>:</span><span class=m>50000</span><span class=l>/udp</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=m>9600</span><span class=p>:</span><span class=m>9600</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>LS_JAVA_OPTS</span><span class=p>:</span><span class=w> </span>-<span class=l>Xms256m -Xmx256m</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>LOGSTASH_INTERNAL_PASSWORD</span><span class=p>:</span><span class=w> </span><span class=l>${LOGSTASH_INTERNAL_PASSWORD:-}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>elasticsearch</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>restart</span><span class=p>:</span><span class=w> </span><span class=l>unless-stopped</span><span class=w>
</span></span></span></code></pre></div><h2 id=配置-logstash-pipeline>配置 logstash pipeline<a hidden class=anchor aria-hidden=true href=#配置-logstash-pipeline>#</a></h2><h3 id=配置-input>配置 input<a hidden class=anchor aria-hidden=true href=#配置-input>#</a></h3><p>因为日志要从 kafka 读取，所以要在 input 块内声明一个新的数据源</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl><span class=n>input</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>beats</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>port</span> <span class=o>=&gt;</span> <span class=mi>5044</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>tcp</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>port</span> <span class=o>=&gt;</span> <span class=mi>50000</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>kafka</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>bootstrap_servers</span> <span class=o>=&gt;</span> <span class=s2>&#34;kafka 地址&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>client_id</span> <span class=o>=&gt;</span> <span class=s2>&#34;test_logstash&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>group_id</span> <span class=o>=&gt;</span> <span class=s2>&#34;test_logstash&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>auto_offset_reset</span> <span class=o>=&gt;</span> <span class=s2>&#34;latest&#34;</span> 
</span></span><span class=line><span class=cl>		<span class=n>consumer_threads</span> <span class=o>=&gt;</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>		<span class=n>decorate_events</span> <span class=o>=&gt;</span> <span class=kp>true</span> 
</span></span><span class=line><span class=cl>		<span class=n>topics</span> <span class=o>=&gt;</span> <span class=o>[</span><span class=s2>&#34;tencent-tke-log&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>		<span class=n>type</span> <span class=o>=&gt;</span> <span class=s2>&#34;bhy&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=配置过滤器>配置过滤器<a hidden class=anchor aria-hidden=true href=#配置过滤器>#</a></h3><p>由于腾讯云投递到kafka的数据不是可以直接用的，数据示例如下</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;@timestamp&#34;</span><span class=p>:</span><span class=mf>1684203000.007603</span><span class=p>,</span><span class=nt>&#34;@filepath&#34;</span><span class=p>:</span><span class=s2>&#34;/var/log/tke-log-agent/log/stdout-containerd/xxxxxxx.log&#34;</span><span class=p>,</span><span class=nt>&#34;log&#34;</span><span class=p>:</span><span class=s2>&#34;2023-05-16T10:10:00.002817673+08:00 stdout F {\&#34;level\&#34;:\&#34;debug\&#34;,\&#34;time\&#34;:\&#34;2023-05-16T10:10:00.002+0800\&#34;,\&#34;msg\&#34;:\&#34;xxxxxxxx\&#34;}&#34;</span><span class=p>,</span><span class=nt>&#34;kubernetes&#34;</span><span class=p>:{</span><span class=nt>&#34;pod_name&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxx&#34;</span><span class=p>,</span><span class=nt>&#34;namespace_name&#34;</span><span class=p>:</span><span class=s2>&#34;default&#34;</span><span class=p>,</span><span class=nt>&#34;pod_id&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxxx&#34;</span><span class=p>,</span><span class=nt>&#34;labels&#34;</span><span class=p>:{</span><span class=nt>&#34;k8s-app&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxx&#34;</span><span class=p>,</span><span class=nt>&#34;pod-template-hash&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxx&#34;</span><span class=p>,</span><span class=nt>&#34;qcloud-app&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxxxxx&#34;</span><span class=p>},</span><span class=nt>&#34;annotations&#34;</span><span class=p>:{</span><span class=nt>&#34;qcloud-redeploy-timestamp&#34;</span><span class=p>:</span><span class=s2>&#34;1681975158658&#34;</span><span class=p>,</span><span class=nt>&#34;tke.cloud.tencent.com/networks-status&#34;</span><span class=p>:</span><span class=s2>&#34;json&#34;</span><span class=p>},</span><span class=nt>&#34;host&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxx&#34;</span><span class=p>,</span><span class=nt>&#34;container_name&#34;</span><span class=p>:</span><span class=s2>&#34;xxxx&#34;</span><span class=p>,</span><span class=nt>&#34;docker_id&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxx&#34;</span><span class=p>,</span><span class=nt>&#34;container_hash&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxxx&#34;</span><span class=p>,</span><span class=nt>&#34;container_image&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxxxxx&#34;</span><span class=p>}}</span>
</span></span></code></pre></div><p>这时候就要对数据进行预处理，因为有很多数据是不需要添加进入es里面的。使用了 logstags 的 filter 进行处理。</p><h4 id=保存原始数据>保存原始数据<a hidden class=anchor aria-hidden=true href=#保存原始数据>#</a></h4><p>这个过滤器添加了一个叫做 source 的字段，并且将 kafka 消息全部存储在里面</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>add_field</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;source&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;%{[message]}&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>  	<span class=p>}</span>
</span></span></code></pre></div><h4 id=解析-json>解析 json<a hidden class=anchor aria-hidden=true href=#解析-json>#</a></h4><p>使用 json 插件，对 message 字段的 json 字符串进行序列化，并且将序列化后的数据存储在 kafkajson 字段内，同时删除 message 字段</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl>	<span class=n>json</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>source</span> <span class=o>=&gt;</span> <span class=s2>&#34;message&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>remove_field</span> <span class=o>=&gt;</span> <span class=o>[</span> 
</span></span><span class=line><span class=cl>			<span class=s2>&#34;message&#34;</span>
</span></span><span class=line><span class=cl>		<span class=o>]</span>
</span></span><span class=line><span class=cl>		<span class=n>target</span> <span class=o>=&gt;</span> <span class=s2>&#34;kafkajson&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span></code></pre></div><h4 id=提取日志元数据>提取日志元数据<a hidden class=anchor aria-hidden=true href=#提取日志元数据>#</a></h4><p>将日志中的一些定位数据提取到外层</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][namespace_name]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;namespace&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][pod_name]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;podname&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][labels][k8s-app]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;k8s-app&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][container_image]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;container-image&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>  	<span class=p>}</span>
</span></span></code></pre></div><h4 id=使用正则表达式处理数据>使用正则表达式处理数据<a hidden class=anchor aria-hidden=true href=#使用正则表达式处理数据>#</a></h4><p>腾讯云给出的数据会在服务自己打印的日志前方添加时间以及 ”stdout F“，所以要使用正则表达式将我们不需要的东西做下替换</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>2023-05-16T10:10:00.002817673+08:00 stdout F <span class=o>{</span><span class=se>\&#34;</span>level<span class=se>\&#34;</span>:<span class=se>\&#34;</span>debug<span class=se>\&#34;</span>,<span class=se>\&#34;</span>time<span class=se>\&#34;</span>:<span class=se>\&#34;</span>2023-05-16T10:10:00.002+0800<span class=se>\&#34;</span>,<span class=se>\&#34;</span>msg<span class=se>\&#34;</span>:<span class=se>\&#34;</span>xxxxx<span class=se>\&#34;</span><span class=o>}</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nb>gsub</span> <span class=o>=&gt;</span> <span class=o>[</span> <span class=s2>&#34;[kafkajson][log]&#34;</span><span class=p>,</span><span class=s2>&#34;.+stdout</span><span class=se>\s</span><span class=s2>F</span><span class=se>\s</span><span class=s2>&#34;</span><span class=p>,</span><span class=s2>&#34;&#34;</span> <span class=o>]</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span></code></pre></div><h4 id=提取服务打印的日志>提取服务打印的日志<a hidden class=anchor aria-hidden=true href=#提取服务打印的日志>#</a></h4><p>这回终于可以将日志提取出来了</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl>	<span class=n>json</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>source</span> <span class=o>=&gt;</span> <span class=s2>&#34;[kafkajson][log]&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>remove_field</span> <span class=o>=&gt;</span> <span class=o>[</span> 
</span></span><span class=line><span class=cl>			<span class=s2>&#34;kafkajson&#34;</span>
</span></span><span class=line><span class=cl>		<span class=o>]</span>
</span></span><span class=line><span class=cl>		<span class=n>target</span> <span class=o>=&gt;</span> <span class=s2>&#34;data&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span></code></pre></div><h4 id=提取日志等级>提取日志等级<a hidden class=anchor aria-hidden=true href=#提取日志等级>#</a></h4><p>最后一步，将日志的等级字段提取到外层，方便使用</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[data][level]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;level&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>  	<span class=p>}</span>
</span></span></code></pre></div><h3 id=完整-pipeline>完整 pipeline<a hidden class=anchor aria-hidden=true href=#完整-pipeline>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-ruby data-lang=ruby><span class=line><span class=cl><span class=n>input</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>beats</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>port</span> <span class=o>=&gt;</span> <span class=mi>5044</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>tcp</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>port</span> <span class=o>=&gt;</span> <span class=mi>50000</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>kafka</span><span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>bootstrap_servers</span> <span class=o>=&gt;</span> <span class=s2>&#34;kafka 地址&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>client_id</span> <span class=o>=&gt;</span> <span class=s2>&#34;test_logstash&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>group_id</span> <span class=o>=&gt;</span> <span class=s2>&#34;test_logstash&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>auto_offset_reset</span> <span class=o>=&gt;</span> <span class=s2>&#34;latest&#34;</span> 
</span></span><span class=line><span class=cl>		<span class=n>consumer_threads</span> <span class=o>=&gt;</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>		<span class=n>decorate_events</span> <span class=o>=&gt;</span> <span class=kp>true</span> 
</span></span><span class=line><span class=cl>		<span class=n>topics</span> <span class=o>=&gt;</span> <span class=o>[</span><span class=s2>&#34;tencent-tke-log&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>		<span class=n>type</span> <span class=o>=&gt;</span> <span class=s2>&#34;bhy&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>filter</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>add_field</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;source&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;%{[message]}&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>  	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=n>json</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>source</span> <span class=o>=&gt;</span> <span class=s2>&#34;message&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>remove_field</span> <span class=o>=&gt;</span> <span class=o>[</span> 
</span></span><span class=line><span class=cl>			<span class=s2>&#34;message&#34;</span>
</span></span><span class=line><span class=cl>		<span class=o>]</span>
</span></span><span class=line><span class=cl>		<span class=n>target</span> <span class=o>=&gt;</span> <span class=s2>&#34;kafkajson&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][namespace_name]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;namespace&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][pod_name]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;podname&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][labels][k8s-app]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;k8s-app&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[kafkajson][kubernetes][container_image]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;container-image&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>  	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nb>gsub</span> <span class=o>=&gt;</span> <span class=o>[</span> <span class=s2>&#34;[kafkajson][log]&#34;</span><span class=p>,</span><span class=s2>&#34;.+stdout</span><span class=se>\s</span><span class=s2>F</span><span class=se>\s</span><span class=s2>&#34;</span><span class=p>,</span><span class=s2>&#34;&#34;</span> <span class=o>]</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=n>json</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>source</span> <span class=o>=&gt;</span> <span class=s2>&#34;[kafkajson][log]&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>remove_field</span> <span class=o>=&gt;</span> <span class=o>[</span> 
</span></span><span class=line><span class=cl>			<span class=s2>&#34;kafkajson&#34;</span>
</span></span><span class=line><span class=cl>		<span class=o>]</span>
</span></span><span class=line><span class=cl>		<span class=n>target</span> <span class=o>=&gt;</span> <span class=s2>&#34;data&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=n>mutate</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    	<span class=n>rename</span> <span class=o>=&gt;</span> <span class=p>{</span> <span class=s2>&#34;[data][level]&#34;</span> <span class=o>=&gt;</span> <span class=s2>&#34;level&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>  	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Add your filters / logstash plugins configuration here</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>elasticsearch</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>hosts</span> <span class=o>=&gt;</span> <span class=s2>&#34;elasticsearch:9200&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>user</span> <span class=o>=&gt;</span> <span class=s2>&#34;logstash_internal&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>password</span> <span class=o>=&gt;</span> <span class=s2>&#34;${LOGSTASH_INTERNAL_PASSWORD}&#34;</span>
</span></span><span class=line><span class=cl>		<span class=n>index</span> <span class=o>=&gt;</span> <span class=s2>&#34;logstash-%{+YYYY-MM-dd}&#34;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=特别鸣谢>特别鸣谢<a hidden class=anchor aria-hidden=true href=#特别鸣谢>#</a></h2><p>在本次配置 logstash 的过程中，我自己搭建的、使用 openAPI API 的、基于 GPT3.5 语言模型的 telegram bot 给予了我很大的帮助。</p><p>以下是我与它的对话(对话内容经过处理)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mysql data-lang=mysql><span class=line><span class=cl><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>18</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>我想从</span><span class=w> </span><span class=mi>2023</span><span class=o>-</span><span class=mi>05</span><span class=o>-</span><span class=mi>15</span><span class=n>T13</span><span class=p>:</span><span class=mi>51</span><span class=p>:</span><span class=mi>00</span><span class=p>.</span><span class=mi>004687384</span><span class=o>+</span><span class=mi>08</span><span class=p>:</span><span class=mi>00</span><span class=w> </span><span class=n>stdout</span><span class=w> </span><span class=n>F</span><span class=w> </span><span class=err>{</span><span class=s2>&#34;level&#34;</span><span class=p>:</span><span class=s2>&#34;debug&#34;</span><span class=p>,</span><span class=s2>&#34;time&#34;</span><span class=p>:</span><span class=s2>&#34;2023-05-15T13:51:00.002+0800&#34;</span><span class=p>,</span><span class=s2>&#34;msg&#34;</span><span class=p>:</span><span class=s2>&#34;xxxxxxxx&#34;</span><span class=err>}</span><span class=w> </span><span class=err>这些数据里面使用</span><span class=n>logstash</span><span class=w> </span><span class=err>提取出</span><span class=n>json数据</span><span class=err>，</span><span class=n>logstash</span><span class=w> </span><span class=err>的</span><span class=n>pipeline该怎么写</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>18</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>假设你的日志文件是以</span><span class=n>JSON格式输出的</span><span class=err>，你需要配置一个</span><span class=n>JSON解析器来解析日志中的JSON数据</span><span class=err>，并将其转换为可用的事件。以下是一个简单的</span><span class=n>Logstash配置文件</span><span class=err>：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>input</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>file</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>path</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;/path/to/your/logfile&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>start_position</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;beginning&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>sincedb_path</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;/dev/null&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>filter</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>json</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>source</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;message&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>output</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>stdout</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>codec</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=n>rubydebug</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>在</span><span class=n>logstash的input部分</span><span class=err>，我们指定读取的文件的路径，以及从文件的开始位置开始读入数据。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>在</span><span class=n>filter部分</span><span class=err>，我们使用</span><span class=o>`</span><span class=n>json</span><span class=o>`</span><span class=err>插件从日志中提取</span><span class=n>json对象</span><span class=err>。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>最后，我们在</span><span class=n>output部分使用</span><span class=o>`</span><span class=n>rubydebug</span><span class=o>`</span><span class=err>进行输出。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>运行这个</span><span class=n>Logstash的配置命令</span><span class=err>：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>bin</span><span class=o>/</span><span class=n>logstash</span><span class=w> </span><span class=o>-</span><span class=n>f</span><span class=w> </span><span class=o>/</span><span class=n>path</span><span class=o>/</span><span class=k>to</span><span class=o>/</span><span class=n>your</span><span class=o>/</span><span class=n>config</span><span class=o>/</span><span class=n>file</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这样，</span><span class=n>logstash就会从你指定的文件中读取数据</span><span class=err>，并把提取的</span><span class=n>JSON对象输出到控制台上</span><span class=err>。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>19</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这个数据有</span><span class=n>json格式的数据</span><span class=err>，但是在</span><span class=n>json格式的数据前面还有一些脏数据</span><span class=err>，是否可以去除？</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>19</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>可以，在使用</span><span class=w> </span><span class=n>logstash</span><span class=w> </span><span class=err>分析数据的时候，可以使用</span><span class=w> </span><span class=n>grok</span><span class=w> </span><span class=err>这个插件，通过正则表达式匹配出需要的数据。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>以下是一个可能符合你提供的数据的</span><span class=w> </span><span class=n>grok</span><span class=w> </span><span class=err>表达式：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>%</span><span class=err>{</span><span class=n>TIMESTAMP_ISO8601</span><span class=p>:</span><span class=kt>timestamp</span><span class=err>}</span><span class=w> </span><span class=n>stdout</span><span class=w> </span><span class=n>F</span><span class=w> </span><span class=o>%</span><span class=err>{</span><span class=n>GREEDYDATA</span><span class=p>:</span><span class=n>json_data</span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这个正则表达式的含义是匹配以</span><span class=w> </span><span class=n>ISO8601</span><span class=w> </span><span class=err>格式表示的时间戳（如</span><span class=w> </span><span class=s2>&#34;2023-05-15T13:51:00.004687384+08:00&#34;</span><span class=err>）和以字符串</span><span class=w> </span><span class=s2>&#34;stdout F &#34;</span><span class=w> </span><span class=err>结尾的内容，然后跟着一个</span><span class=w> </span><span class=n>Json</span><span class=w> </span><span class=err>格式的字符串。</span><span class=s2>&#34;%{GREEDYDATA:json_data}&#34;</span><span class=w> </span><span class=err>表示将这个字符串保存到一个名为</span><span class=w> </span><span class=s2>&#34;json_data&#34;</span><span class=w> </span><span class=err>的字段中。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>上述</span><span class=w> </span><span class=n>grok</span><span class=w> </span><span class=err>表达式可以在</span><span class=w> </span><span class=n>Logstash</span><span class=w> </span><span class=err>的配置文件中使用，例如：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>input</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1># 配置 logstash 接收数据的源
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>filter</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>grok</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>match</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=s2>&#34;message&#34;</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;%{TIMESTAMP_ISO8601:timestamp} stdout F %{GREEDYDATA:json_data}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1># 其他过滤器
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>output</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1># 配置 logstash 输出数据的目标
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这个配置文件中，通过</span><span class=w> </span><span class=n>filter</span><span class=w> </span><span class=err>下的</span><span class=w> </span><span class=n>grok</span><span class=w> </span><span class=err>插件匹配出了</span><span class=w> </span><span class=kt>timestamp</span><span class=w> </span><span class=err>和</span><span class=w> </span><span class=n>json_data</span><span class=w> </span><span class=err>两个字段。从而可以使用</span><span class=w> </span><span class=n>logstash</span><span class=w> </span><span class=err>利用这些数据进行更进一步的操作，如输出到</span><span class=w> </span><span class=n>Elasticsearch</span><span class=w> </span><span class=err>或者</span><span class=w> </span><span class=n>stdout</span><span class=err>。达到你想要的结果。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>其中</span><span class=w> </span><span class=o>`%</span><span class=err>{</span><span class=n>TIMESTAMP_ISO8601</span><span class=p>:</span><span class=kt>timestamp</span><span class=err>}</span><span class=o>`</span><span class=w> </span><span class=err>表示匹配</span><span class=w> </span><span class=n>ISO8601</span><span class=w> </span><span class=err>格式的时间戳，并将其保存到一个名为</span><span class=w> </span><span class=s2>&#34;timestamp&#34;</span><span class=w> </span><span class=err>的字段中。</span><span class=o>`%</span><span class=err>{</span><span class=n>GREEDYDATA</span><span class=p>:</span><span class=n>json_data</span><span class=err>}</span><span class=o>`</span><span class=w> </span><span class=err>表示匹配任意字符，可以匹配行末附加的不符合</span><span class=w> </span><span class=n>Json</span><span class=w> </span><span class=err>格式的内容。因为</span><span class=w> </span><span class=n>grok</span><span class=w> </span><span class=err>会一直匹配到行尾，所以匹配过程中会包括最后一个字段（即</span><span class=w> </span><span class=n>json_data</span><span class=err>）中包含的所有内容。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>36</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>返回</span><span class=w> </span><span class=n>Can</span><span class=s1>&#39;t get text on a START_OBJECT at 1:8 是什么错误
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>openAI, [5/15/23 2:36 PM]
</span></span></span><span class=line><span class=cl><span class=s1>这个错误常见于尝试将 JSON 对象作为字符串进行解析的情况下，但是实际上得到的是 JSON 对象，而不是字符串。这意味着该对象的开头是一个“{”，而不是一个“&#34;”。可以检查代码调用的函数或方法，以确保解析的字符串确实是一个字符串。另外，可以检查 JSON 对象的源代码，以确保它是按照预期格式进行编写的。
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>johnpoint, [5/15/23 2:53 PM]
</span></span></span><span class=line><span class=cl><span class=s1>[2023-05-15T06:52:48,511][WARN ][logstash.filters.json    ][main][xxxxxx] Error parsing json {:source=&gt;&#34;json_data&#34;, :raw=&gt;&#34;{\\\&#34;level\\\&#34;:\\\&#34;debug\\\&#34;,\\\&#34;time\\\&#34;:\\\&#34;2023-05-15T14:52:47.664+0800\\\&#34;,\\\&#34;msg\\\&#34;:\\\&#34;xxxxxxxx\\\&#34;}\&#34;, \&#34;@timestamp\&#34;=&gt;0.1684133567674155e10}&#34;, :exception=&gt;#&lt;LogStash::Json::ParserError: Unexpected character (&#39;</span><span class=err>\</span><span class=s1>&#39; (code 92)): was expecting double-quote to start field name
</span></span></span><span class=line><span class=cl><span class=s1>这行日志表示 logstash 有什么问题呢
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>openAI, [5/15/23 2:53 PM]
</span></span></span><span class=line><span class=cl><span class=s1>这行日志表示 Logstash 在解析输入数据 json_data 时遇到了编码问题，其中输入数据包含了 `\&#39;</span><span class=o>`</span><span class=w> </span><span class=err>等不符合</span><span class=w> </span><span class=n>JSON</span><span class=w> </span><span class=err>规范的字符，导致</span><span class=w> </span><span class=n>JSON</span><span class=w> </span><span class=err>解析器无法正确解析。具体来说，可能是输入数据中使用了反斜线对引号进行转义，而又没有正确地对反斜线本身进行转义。可以尝试对输入数据进行预处理，将不符合</span><span class=w> </span><span class=n>JSON</span><span class=w> </span><span class=err>规范的字符进行转义或删除，以便让</span><span class=w> </span><span class=n>Logstash</span><span class=w> </span><span class=err>能够正确解析数据。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>53</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>可以给出相对应</span><span class=w> </span><span class=err>的</span><span class=w> </span><span class=n>pipeline</span><span class=w> </span><span class=err>配置吗</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>53</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>好的，以下是一个简单的</span><span class=w> </span><span class=n>Logstash</span><span class=w> </span><span class=n>Pipeline</span><span class=w> </span><span class=err>配置，用于从输入中提取</span><span class=w> </span><span class=o>`</span><span class=n>json_data</span><span class=o>`</span><span class=w> </span><span class=err>字段，并过滤掉任何无效数据：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=n>conf</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>input</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1># 在这里配置输入插件
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>  </span><span class=n>stdin</span><span class=w> </span><span class=err>{}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>filter</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1># 从 json_data 字段提取 JSON 数据
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>  </span><span class=n>json</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>source</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;json_data&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1># 用于忽略不完整的 JSON 数据字符串
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>    </span><span class=n>skip_on_invalid_json</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=no>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1># 过滤掉没有有效 JSON 数据的事件
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>  </span><span class=k>if</span><span class=w> </span><span class=s2>&#34;_jsonparsefailure&#34;</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=p>[</span><span class=n>tags</span><span class=p>]</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>drop</span><span class=w> </span><span class=err>{}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>output</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1># 在这里配置输出插件
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>  </span><span class=n>stdout</span><span class=w> </span><span class=err>{}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>您需要根据自己的需求进行相应的修改和调整，比如将</span><span class=w> </span><span class=o>`</span><span class=n>json_data</span><span class=o>`</span><span class=w> </span><span class=err>改成实际的字段名，或者使用适合您的输入和输出插件。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>54</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>使用</span><span class=n>grok提取的json数据会多出不必要的转义反斜杠</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>2</span><span class=p>:</span><span class=mi>54</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>是的，这是因为</span><span class=w> </span><span class=n>Grok</span><span class=w> </span><span class=err>模式匹配时会将反斜杠视为转义字符，因此如果日志中原本就有反斜杠，会被额外转义。为了解决这个问题，可以在配置文件中使用</span><span class=w> </span><span class=n>gsub</span><span class=w> </span><span class=err>过滤器去除多余的反斜杠。示例配置如下：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>input</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>stdin</span><span class=w> </span><span class=err>{</span><span class=w> </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>filter</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>grok</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>match</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=err>{</span><span class=w> </span><span class=s2>&#34;message&#34;</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s1>&#39;^\[%{TIMESTAMP_ISO8601:timestamp}\]\[%{WORD:log_level}\] %{GREEDYDATA:json_data}$&#39;</span><span class=w> </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>mutate</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>gsub</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;json_data&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;\\\\&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;\\&#34;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>json</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>source</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;json_data&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>output</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>stdout</span><span class=w> </span><span class=err>{</span><span class=w> </span><span class=n>codec</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=n>rubydebug</span><span class=w> </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这个配置中首先使用</span><span class=w> </span><span class=n>Grok</span><span class=w> </span><span class=err>解析出日志中的</span><span class=w> </span><span class=n>JSON</span><span class=w> </span><span class=err>数据，并将其存储到</span><span class=w> </span><span class=o>`</span><span class=n>json_data</span><span class=o>`</span><span class=w> </span><span class=err>字段中。然后使用</span><span class=w> </span><span class=o>`</span><span class=n>mutate</span><span class=o>`</span><span class=w> </span><span class=err>过滤器中的</span><span class=w> </span><span class=o>`</span><span class=n>gsub</span><span class=o>`</span><span class=w> </span><span class=err>将多余的反斜杠替换掉，最后使用</span><span class=w> </span><span class=o>`</span><span class=n>json</span><span class=o>`</span><span class=w> </span><span class=err>过滤器将其转换成</span><span class=w> </span><span class=n>JSON</span><span class=w> </span><span class=err>格式的事件。这样就可以避免多出不必要的反斜杠了。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>00</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>报错了</span><span class=w> </span><span class=n>Failed</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>execute</span><span class=w> </span><span class=n>action</span><span class=w> </span><span class=err>{</span><span class=p>:</span><span class=n>action</span><span class=o>=&gt;</span><span class=n>LogStash</span><span class=p>::</span><span class=n>PipelineAction</span><span class=p>::</span><span class=k>Create</span><span class=o>/</span><span class=n>pipeline_id</span><span class=p>:</span><span class=n>main</span><span class=p>,</span><span class=w> </span><span class=p>:</span><span class=n>exception</span><span class=o>=&gt;</span><span class=s2>&#34;LogStash::ConfigurationError&#34;</span><span class=p>,</span><span class=w> </span><span class=p>:</span><span class=n>message</span><span class=o>=&gt;</span><span class=s2>&#34;Expected one of [ \\t\\r\\n], \&#34;</span><span class=c1>#\&#34;, \&#34;{\&#34;, \&#34;,\&#34;, \&#34;]\&#34; at line 36, column 34 (byte 672) after filter {\n\tjson {\n\t\tsource =&gt; \&#34;message\&#34;\n\t\tremove_field =&gt; [ \n\t\t\t\&#34;message\&#34;\n\t\t]\n\t\ttarget =&gt; \&#34;kafkajson\&#34;\n\t}\n\tgrok {\n\t\tmatch =&gt; {\&#34;kafkajson\&#34; =&gt; \&#34;%{TIMESTAMP_ISO8601:timestamp} stdout F %{GREEDYDATA:json_data}\&#34;}\n\t}\n\tmutate {\n\t\tgsub =&gt; [\&#34;json_data\&#34;, \&#34;\\\\\\\\\&#34;, \&#34;&#34;, :backtrace=&gt;[&#34;/usr/share/logstash/logstash-core/lib/logstash/compiler.rb:32:in `compile_imperative&#39;&#34;, &#34;org/logstash/execution/AbstractPipelineExt.java:187:in `initialize&#39;&#34;, &#34;org/logstash/execution/JavaBasePipelineExt.java:72:in `initialize&#39;&#34;, &#34;/usr/share/logstash/logstash-core/lib/logstash/java_pipeline.rb:47:in `initialize&#39;&#34;, &#34;/usr/share/logstash/logstash-core/lib/logstash/pipeline_action/create.rb:52:in `execute&#39;&#34;, &#34;/usr/share/logstash/logstash-core/lib/logstash/agent.rb:383:in `block in converge_state&#39;&#34;]}
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>00</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这个错误是在</span><span class=w> </span><span class=n>Logstash</span><span class=w> </span><span class=err>配置文件中，第</span><span class=mi>36</span><span class=err>行，第</span><span class=mi>34</span><span class=err>列（</span><span class=mi>672</span><span class=err>个字节）处，期望看到</span><span class=w> </span><span class=o>`</span><span class=p>[</span><span class=w> </span><span class=err>\</span><span class=n>t</span><span class=err>\</span><span class=n>r</span><span class=err>\</span><span class=n>n</span><span class=p>]</span><span class=s2>&#34;, &#34;</span><span class=c1>#&#34;, &#34;{&#34;, &#34;,&#34;, &#34;]&#34;` 中的一个字符，但是实际遇到的字符无法按预期解析。这可能是因为语法错误或表达式不正确导致的。请检查您的配置文件并确保语法正确，并解决任何表达式错误。
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>另外，由于错误信息无法提供足够的上下文，您还可能需要检查其他部分的配置文件以确定是否存在其他错误。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>15</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>logstash</span><span class=w> </span><span class=err>可以将一个字段的数据移动到另一个字段里面去吗</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>15</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>可以的，可以使用</span><span class=n>logstash的filter插件中的mutate插件的rename选项来实现</span><span class=p>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>例如，如果数据来源的字段名为</span><span class=o>`</span><span class=n>source_field</span><span class=o>`</span><span class=err>，想要将其复制到目标字段</span><span class=o>`</span><span class=n>target_field</span><span class=o>`</span><span class=err>，可以使用以下配置</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>filter</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>mutate</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>rename</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=err>{</span><span class=w> </span><span class=s2>&#34;source_field&#34;</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;target_field&#34;</span><span class=w> </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这将把</span><span class=o>`</span><span class=n>source_field</span><span class=o>`</span><span class=err>的值复制到新字段</span><span class=o>`</span><span class=n>target_field</span><span class=o>`</span><span class=err>中，并删除</span><span class=o>`</span><span class=n>source_field</span><span class=o>`</span><span class=err>字段本身。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>19</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>如果我要保留这个字段呢</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>19</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>可以使用</span><span class=w> </span><span class=n>mutate</span><span class=w> </span><span class=err>插件的</span><span class=w> </span><span class=n>add_field</span><span class=w> </span><span class=err>选项，用于在事件中创建新字段。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>比如，如果您想要在</span><span class=w> </span><span class=n>Logstash</span><span class=w> </span><span class=err>事件中创建一个新字段</span><span class=w> </span><span class=s2>&#34;new_field&#34;</span><span class=w> </span><span class=err>并从原始字段</span><span class=w> </span><span class=s2>&#34;old_field&#34;</span><span class=w> </span><span class=err>中移动其值：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>filter</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>mutate</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>     </span><span class=n>add_field</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=err>{</span><span class=w> </span><span class=s2>&#34;new_field&#34;</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;%{[old_field]}&#34;</span><span class=w> </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>     </span><span class=n>remove_field</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=p>[</span><span class=w> </span><span class=s2>&#34;old_field&#34;</span><span class=w> </span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>这将将</span><span class=w> </span><span class=s2>&#34;old_field&#34;</span><span class=w> </span><span class=err>中的值赋给新的</span><span class=w> </span><span class=s2>&#34;new_field&#34;</span><span class=w> </span><span class=err>字段，并将删除</span><span class=w> </span><span class=s2>&#34;old_field&#34;</span><span class=w> </span><span class=err>字段。</span><span class=w> </span><span class=err>如果您想在保留源字段的同时移动值，可以将</span><span class=w> </span><span class=s2>&#34;remove_field&#34;</span><span class=w> </span><span class=err>选项删除。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>21</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>logstash</span><span class=w> </span><span class=err>删除自动创建</span><span class=w> </span><span class=n>keyword</span><span class=w> </span><span class=err>字段</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>3</span><span class=p>:</span><span class=mi>21</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>Logstash</span><span class=w> </span><span class=err>中默认会为每个字符串类型的字段创建一个</span><span class=w> </span><span class=o>`</span><span class=n>keyword</span><span class=o>`</span><span class=w> </span><span class=err>类型的子字段，作为原始字段的精确值。如果你不需要这个子字段，可以在索引模板（</span><span class=n>template</span><span class=err>）中将它移除：在</span><span class=w> </span><span class=o>`</span><span class=n>mappings</span><span class=o>`</span><span class=w> </span><span class=err>中设置</span><span class=w> </span><span class=o>`</span><span class=s2>&#34;include_in_all&#34;</span><span class=p>:</span><span class=w> </span><span class=no>false</span><span class=o>`</span><span class=w> </span><span class=err>即可。但需要注意的是，使用该方法删除</span><span class=w> </span><span class=o>`</span><span class=n>keyword</span><span class=o>`</span><span class=w> </span><span class=err>字段会导致失去部分精确查询的能力。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>如果你想要在日志流中保留</span><span class=w> </span><span class=o>`</span><span class=n>keyword</span><span class=o>`</span><span class=w> </span><span class=err>字段，可以使用</span><span class=w> </span><span class=o>`</span><span class=n>remove_field</span><span class=o>`</span><span class=w> </span><span class=err>过滤器来删除原始字段，但保留</span><span class=w> </span><span class=o>`</span><span class=n>keyword</span><span class=o>`</span><span class=w> </span><span class=err>字段：</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=n>ruby</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>filter</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>mutate</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>remove_field</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;my_field&#34;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>rename</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=err>{</span><span class=w> </span><span class=s2>&#34;my_field.keyword&#34;</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;new_field&#34;</span><span class=w> </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>上面的例子中，</span><span class=n>Logstash</span><span class=w> </span><span class=err>会删除原始的</span><span class=w> </span><span class=o>`</span><span class=n>my_field</span><span class=o>`</span><span class=w> </span><span class=err>字段，并将精确值保存在</span><span class=w> </span><span class=o>`</span><span class=n>my_field</span><span class=p>.</span><span class=n>keyword</span><span class=o>`</span><span class=w> </span><span class=err>子字段中，最后使用</span><span class=w> </span><span class=o>`</span><span class=k>rename</span><span class=o>`</span><span class=w> </span><span class=err>过滤器，将</span><span class=w> </span><span class=o>`</span><span class=n>my_field</span><span class=p>.</span><span class=n>keyword</span><span class=o>`</span><span class=w> </span><span class=err>重命名为</span><span class=w> </span><span class=o>`</span><span class=n>new_field</span><span class=o>`</span><span class=err>。这样，你就可以在</span><span class=w> </span><span class=n>Elasticsearch</span><span class=w> </span><span class=err>中使用</span><span class=w> </span><span class=o>`</span><span class=n>new_field</span><span class=o>`</span><span class=w> </span><span class=err>进行精确查询。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>4</span><span class=p>:</span><span class=mi>18</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>logstash</span><span class=w> </span><span class=err>为什么创建的</span><span class=w> </span><span class=n>es</span><span class=w> </span><span class=k>index</span><span class=w> </span><span class=err>没有每天滚动的名字</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>4</span><span class=p>:</span><span class=mi>18</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>logstash</span><span class=w> </span><span class=err>创建</span><span class=w> </span><span class=n>ES</span><span class=w> </span><span class=k>index</span><span class=w> </span><span class=err>默认采用的是</span><span class=w> </span><span class=n>Daily</span><span class=w> </span><span class=k>Index</span><span class=w> </span><span class=err>的模式，每天一个</span><span class=w> </span><span class=k>Index</span><span class=err>，并且附带日期的后缀。例如，一个名为</span><span class=w> </span><span class=o>`</span><span class=n>logstash</span><span class=o>`</span><span class=w> </span><span class=err>的索引将被转换成</span><span class=w> </span><span class=o>`</span><span class=n>logstash</span><span class=o>-</span><span class=n>yyyy</span><span class=p>.</span><span class=n>mm</span><span class=p>.</span><span class=n>dd</span><span class=o>`</span><span class=w> </span><span class=err>的名字，在写入数据时，会根据</span><span class=w> </span><span class=n>UTC</span><span class=w> </span><span class=err>时区来决定对应日期的具体值。如果没有滚动，一种可能是配置文件中未启用，还有一个可能是</span><span class=w> </span><span class=n>Elasticsearch</span><span class=w> </span><span class=err>集群配置文件设置了禁止创建新</span><span class=w> </span><span class=k>index</span><span class=err>，可以检查一下</span><span class=w> </span><span class=n>Elasticsearch</span><span class=w> </span><span class=err>的配置文件中的相关设置。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>johnpoint</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>4</span><span class=p>:</span><span class=mi>19</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>logstash</span><span class=w> </span><span class=err>怎么开启</span><span class=w> </span><span class=n>Daily</span><span class=w> </span><span class=k>Index</span><span class=w> </span><span class=err>模式</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>openAI</span><span class=p>,</span><span class=w> </span><span class=p>[</span><span class=mi>5</span><span class=o>/</span><span class=mi>15</span><span class=o>/</span><span class=mi>23</span><span class=w> </span><span class=mi>4</span><span class=p>:</span><span class=mi>19</span><span class=w> </span><span class=n>PM</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>要开启</span><span class=w> </span><span class=n>Daily</span><span class=w> </span><span class=k>Index</span><span class=w> </span><span class=err>模式，需要修改</span><span class=w> </span><span class=n>Logstash</span><span class=w> </span><span class=err>的配置文件。在</span><span class=w> </span><span class=o>`</span><span class=n>output</span><span class=o>`</span><span class=w> </span><span class=err>配置中，可以使用</span><span class=w> </span><span class=o>`</span><span class=k>index</span><span class=o>`</span><span class=w> </span><span class=err>配置项来指定</span><span class=w> </span><span class=n>Elasticsearch</span><span class=w> </span><span class=err>索引的名称。为了让索引名称按日滚动，可使用日期格式占位符，例如：</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>output</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>elasticsearch</span><span class=w> </span><span class=err>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>hosts</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;localhost:9200&#34;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>index</span><span class=w> </span><span class=o>=&gt;</span><span class=w> </span><span class=s2>&#34;your-index-name-%{+YYYY.MM.dd}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>在上述配置中，索引名称的格式为</span><span class=w> </span><span class=o>`</span><span class=n>your</span><span class=o>-</span><span class=k>index</span><span class=o>-</span><span class=n>name</span><span class=o>-</span><span class=n>YYYY</span><span class=p>.</span><span class=n>MM</span><span class=p>.</span><span class=n>dd</span><span class=o>`</span><span class=err>，其中</span><span class=w> </span><span class=o>`%</span><span class=err>{</span><span class=o>+</span><span class=n>YYYY</span><span class=p>.</span><span class=n>MM</span><span class=p>.</span><span class=n>dd</span><span class=err>}</span><span class=o>`</span><span class=w> </span><span class=err>是一个日期格式占位符，表示当前日期。这样配置后，每天会自动创建一个新的索引。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>还需注意的是，为了启用</span><span class=w> </span><span class=kt>Date</span><span class=w> </span><span class=k>Index</span><span class=w> </span><span class=err>模式，需要在</span><span class=w> </span><span class=n>Elasticsearch</span><span class=w> </span><span class=err>的配置文件中将</span><span class=w> </span><span class=o>`</span><span class=n>action</span><span class=p>.</span><span class=n>auto_create_index</span><span class=o>`</span><span class=w> </span><span class=err>设置为</span><span class=w> </span><span class=o>`</span><span class=no>true</span><span class=o>`</span><span class=err>。</span><span class=w>
</span></span></span></code></pre></div><h2 id=参考文档>参考文档<a hidden class=anchor aria-hidden=true href=#参考文档>#</a></h2><ul><li><a href=https://github.com/deviantony/docker-elk>Github: deviantony/docker-elk</a></li><li><a href=https://www.elastic.co/guide/en/logstash/current/plugins-filters-json.html>JSON filter plugin</a></li><li><a href=https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate>Mutate filter plugin</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.lvcshu.com/tags/logstash/>Logstash</a></li><li><a href=https://blog.lvcshu.com/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/>腾讯云</a></li><li><a href=https://blog.lvcshu.com/tags/%E7%AC%94%E8%AE%B0/>笔记</a></li></ul><nav class=paginav><a class=prev href=https://blog.lvcshu.com/2023/07/13/%E6%88%91%E4%BB%AC%E8%A6%81%E5%AF%B9-newsletter-%E8%AF%B4%E4%B8%8D%E5%90%97/><span class=title>« Prev</span><br><span>我们要对 Newsletter 说不(吗？)</span>
</a><a class=next href=https://blog.lvcshu.com/2022/12/29/2022-year-summary/><span class=title>Next »</span><br><span>2022 年度总结</span></a></nav><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://johnpoints-blog-hexo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.lvcshu.com/>johnpoint's blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script async src=https://umami.uipo.cc/script.js data-website-id=7319ce07-a672-4d99-bf07-9ebb227d449d></script></body></html>